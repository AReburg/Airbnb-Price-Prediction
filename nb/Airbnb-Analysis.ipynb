{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb - Price Modelling\n",
    "#### How to use OpenStreetMap for Feature Engineering and Price Prediction\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "* [Introduction](#introduction)\n",
    "    * [Business Understanding](#business-understanding)\n",
    "    * [Data Understanding](#data-understanding)\n",
    "* [Methods](#methods)\n",
    "    * [Setup](#set-up)\n",
    "    * [Data Engineering](#data-enginering)\n",
    "    * [Outlier Removal](#outlier-removal)\n",
    "    * [Missing Data](#missing-data)\n",
    "    * [Data Exploration](#data-exploration)\n",
    "* [Results/Business Understanding](#results-business-understanding)\n",
    "    * [Where are the most listings in Vienna?](#results-most-listings)\n",
    "    * [How does the district affect the price?](#results-price-district)\n",
    "    * [What types of listings are available?](#results-listings-type)\n",
    "    * [How do weekends affect pricing?](#results-weekend-price)\n",
    "    * [How is the number of reviews changing over time?](#results-reviews-over-time)    \n",
    "    * [How can OpenStreetMap Location Data can be utilized for price prediction?](#osm-features)   \n",
    "    \n",
    "        \n",
    "\n",
    "### Introduction <a class=\"anchor\" id=\"introduction\"></a>\n",
    "Airbnb operates as an online marketplace focused on short-term homestays and experiences. The company acts as a broker and charges a commission from each booking. It connects hosts and travelers and enables the process of renting without owning any rooms itself. Airbnb cultivates the sharing economy which allows property owners to rent out private flats. In this sense it is a community-based online platform for listing and renting local homes.\n",
    "\n",
    "The projects aim is to do a analysis as part of Udacity's Data Science Nanodegree and is structured according to the Cross-Industry Standard Process for Data Mining (CRISP-DM).\n",
    "\n",
    "#### Business Understanding <a class=\"anchor\" id=\"business-understanding\"></a>\n",
    "Defining the purpose of this analysis the following business questions are proposed:\n",
    "\n",
    "- Where are the most listings in Vienna?\n",
    "- How does the district affect the price?\n",
    "- What types of listings are available?\n",
    "- How do weekends affect pricing?\n",
    "- How can OpenStreetMap Location Data can be utilized for price prediction?\n",
    "\n",
    "#### Data Understanding <a class=\"anchor\" id=\"data-understanding\"></a>\n",
    "These questions will be addressed in the analysis of the data provided by inside Airbnb [data](http://insideairbnb.com/get-the-data).\n",
    "\n",
    "### Methods <a class=\"anchor\" id=\"methods\"></a>\n",
    "#### Setup <a class=\"anchor\" id=\"setup\"></a>\n",
    "Import libraries and load the data. In case the package is not installed use the following code for installation:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "!{sys.executable} -m pip install geojson\n",
    "# alternative: pip install osmnx --user\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules/libraries\n",
    "import warnings \n",
    "warnings.simplefilter(action='ignore')\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import time\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import os\n",
    "import pickle\n",
    "import geojson\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.multipolygon import MultiPolygon\n",
    "import chardet\n",
    "from scipy import spatial\n",
    "from scipy.spatial import KDTree\n",
    "from shapely import wkt\n",
    "\n",
    "cwd = Path().resolve()\n",
    "\n",
    "# visualisation\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl \n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Engineering <a class=\"anchor\" id=\"data-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the airbnb data\n",
    "df = pd.read_csv(os.path.join(Path(cwd).parent, 'data', 'listings.csv.gz'), encoding='utf-8')\n",
    "df.drop(['listing_url', 'host_picture_url', 'host_verifications', 'host_thumbnail_url', 'host_about', 'neighborhood_overview', 'picture_url', 'scrape_id', 'neighbourhood_group_cleansed', 'calculated_host_listings_count_shared_rooms', 'calculated_host_listings_count_private_rooms','calculated_host_listings_count_entire_homes'], axis=1, inplace=True)\n",
    "df = df[['id', 'name','description', 'host_name','host_since', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost','host_listings_count','host_total_listings_count', 'host_has_profile_pic','host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms_text', 'bedrooms', 'beds', 'amenities','price']]\n",
    "df['neighbourhood'] = df['neighbourhood_cleansed']\n",
    "df.drop(['neighbourhood_cleansed'], axis=1, inplace=True)\n",
    "\n",
    "df_cal = pd.read_csv(os.path.join(Path(cwd).parent, 'data', 'calendar.csv.gz'), encoding='utf-8')\n",
    "df_rev = pd.read_csv(os.path.join(Path(cwd).parent, 'data', 'reviews.csv'), index_col=False, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Get propper unicode coding for pandas import:\n",
    "\n",
    "```python\n",
    "with open(os.path.join(Path(cwd).parent, 'data', 'listings.csv.gz'),'rb') as f:\n",
    "        data = f.read(800000)\n",
    "encoding=chardet.detect(data).get(\"encoding\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(df, group='', agge='', rename=''):\n",
    "    \"\"\" function to group, aggregate and rename the dataframe \"\"\"\n",
    "    df = df.groupby([group]).agg(agge)\n",
    "    df.columns = df.columns.droplevel(0)\n",
    "    df.columns = rename\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def tukey_rule(data_frame, column_name):\n",
    "    \"\"\" apply tukey rule to remove outliers \"\"\"\n",
    "    data = data_frame[column_name]\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    max_value = Q3 + 1.5 * IQR\n",
    "    min_value = Q1 - 1.5 * IQR\n",
    "\n",
    "    return data_frame[(data_frame[column_name] < max_value) & (data_frame[column_name] > min_value)]\n",
    "\n",
    "\n",
    "def visualize_outliers(df, title):\n",
    "    \"\"\" \"\"\"\n",
    "    fig = go.Figure()\n",
    "    for district in df['neighbourhood'].unique().tolist()[0:3]:\n",
    "        fig.add_trace(go.Violin(x=df['neighbourhood'][df['neighbourhood'] == district],\n",
    "                                y=df['price'][df['neighbourhood'] == district],\n",
    "                                name=district, legendgroup='neighbourhood',\n",
    "                                line_color='blue',\n",
    "                                width=0.8, box_visible=True, meanline_visible=True))\n",
    "    fig.update_layout(font=dict(family=\"Helvetica\"))\n",
    "    fig.update_traces(box_visible=True, meanline_visible=True)\n",
    "    fig.update_layout(violinmode=\"overlay\", violingap=0)\n",
    "    fig.update_layout(violinmode='group')\n",
    "    fig.update_layout(title=title)\n",
    "    fig.update_layout(yaxis_title=\"Median price in $\")\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=400)\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "def get_price(price_string):\n",
    "    \"\"\" convert the price string into float \"\"\"\n",
    "    try:\n",
    "        price_string = price_string.replace(' ', '')\n",
    "        pattern = re.compile(r'\\d{1,3}(?:[.,]\\d{3})*(?:[.,]\\d{2})?')\n",
    "        return float(pattern.findall(price_string)[0].replace(',',''))\n",
    "    except:\n",
    "        print(price_string)\n",
    "\n",
    "def remove_pct(rate):\n",
    "    \"\"\" \"\"\"\n",
    "    try:\n",
    "        return int(rate.replace('%', ''))\n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "        \n",
    "def convert_dtype(df, cols_cur):\n",
    "    \"\"\"convert price & adjusted price dtype from object to float (without $) \"\"\"\n",
    "    for col in cols_cur:\n",
    "        df[col] = df[col].str.replace('$','')\n",
    "        df[col] = df[col].str.replace(',', '').astype(float)\n",
    "\n",
    "\n",
    "df['host_response_rate'] = df.apply(lambda x: remove_pct(x['host_response_rate']), axis=1)\n",
    "df['host_acceptance_rate'] = df.apply(lambda x: remove_pct(x['host_acceptance_rate']), axis=1)\n",
    "df['id'] = df['id'].astype('category')\n",
    "pd.to_numeric(df['host_response_rate'])\n",
    "pd.to_numeric(df['host_acceptance_rate'])\n",
    "\n",
    "convert_dtype(df_cal, ['price', 'adjusted_price'])\n",
    "df_cal['date'] = pd.to_datetime(df_cal['date'])\n",
    "df_cal['available'] = df_cal['available'].apply(lambda x: 1 if x == 't' else 0)\n",
    "df_cal['weekend'] = np.where((pd.DatetimeIndex(df_cal.date).dayofweek==4) | (pd.DatetimeIndex(df_cal.date).dayofweek==5), True, False)\n",
    "df_cal = df_cal.merge(df[['id', 'name', 'host_since', 'neighbourhood', 'host_is_superhost', 'latitude', 'longitude', 'room_type']], how='left', left_on='listing_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = df.apply(lambda x: get_price(x['price']), axis=1)\n",
    "\n",
    "df['neighbourhood'] = df['neighbourhood'].str.replace('Landstra§e', 'Landstraße')\n",
    "df['neighbourhood'] = df['neighbourhood'].str.replace('Rudolfsheim-Fnfhaus', 'Rudolfsheim-Fünfhaus')\n",
    "df['neighbourhood'] = df['neighbourhood'].str.replace('Dbling', 'Döbling')\n",
    "df['neighbourhood'] = df['neighbourhood'].str.replace('Whring', 'Währing')\n",
    "\n",
    "\n",
    "# set data types\n",
    "df_rev['date'] = pd.to_datetime(df_rev['date'])\n",
    "df['host_since'] = pd.to_datetime(df['host_since'])\n",
    "df['host_for'] = (pd.to_datetime('2022-11-05')-df['host_since']).dt.days# / pd.Timedelta(hours=1) #.astype('timedelta64[h]')\n",
    "pd.to_numeric(df['host_for'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier Removal  <a class=\"anchor\" id=\"outlier-removal\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_orig = df.copy()\n",
    "\n",
    "for column in ['price']:\n",
    "    df = tukey_rule(df, column)\n",
    "    \n",
    "visualize_outliers(df_orig, 'Prices of original data set')\n",
    "visualize_outliers(df, 'Prices after outlier removal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data  <a class=\"anchor\" id=\"missing-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing data percent wise of the column\n",
    "dfm = round(df.isnull().mean()*100,2)\n",
    "missing_value_df = pd.DataFrame({'column': dfm.index, 'percentage': dfm.values}).sort_values('percentage', ascending=False)\n",
    "missing_value_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration  <a class=\"anchor\" id=\"data-exploration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numerical data exploration\n",
    "df.select_dtypes(include=np.number).hist(figsize=(16, 10), bins=50, log=False)\n",
    "plt.suptitle('Feature Distributions', y=1.0)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_distribution(df, column, table):\n",
    "    \"\"\"\n",
    "    Aggregates and sorts categorical data of one independent variable and plots bar chart with normal and log scale \n",
    "    INPUT:\n",
    "        df - dataframe with selected data\n",
    "        column - column with independent variable to be aggregated and sorted     \n",
    "    OUTPUT:\n",
    "        2 bar charts: left bar chart shows independent variable with normal scale count and \n",
    "        right bar chart shows independent variable with logaritmic scale count\n",
    "    \"\"\"\n",
    "    agg = df.groupby(column).agg(nr_listings = ('id', 'count')).reset_index()\\\n",
    "                         .sort_values('nr_listings', ascending = False)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 4))\n",
    "\n",
    "    agg.plot(x = column, y = 'nr_listings', kind = 'bar', ax = ax[0], legend = False, grid = True, log = False)\n",
    "    ax[0].set_ylabel('number listings')\n",
    "    ax[0].set_xlabel('')\n",
    "\n",
    "    agg.plot(x = column, y = 'nr_listings', kind = 'bar', ax = ax[1], legend = False, grid = True, log = True)\n",
    "    ax[1].set_title('log scale')\n",
    "    ax[1].set_ylabel('log (number listings)')\n",
    "    ax[1].set_xlabel('')\n",
    "    \n",
    "    fig.suptitle(('distribution number listings over ' + column.title()), y = 1.05)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    agg['proportion [%]'] = round(100 * agg['nr_listings'] / agg['nr_listings'].sum(), 1)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What types of listings are available? <a class=\"anchor\" id=\"results-listings-type\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display bar charts for all columns with categorical data in normal and  logarithmic scale\n",
    "neigh = categorical_distribution(df, 'room_type', table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_type = categorical_distribution(df, 'property_type', table=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airbnb hosts can list entire homes/apartments, private, shared rooms, and more recently hotel rooms. \n",
    "Depending on the room type and activity, a residential airbnb listing could be more like a hotel, disruptive for neighbours, taking away housing, and illegal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding  <a class=\"anchor\" id=\"results-business-understanding\"></a>\n",
    "#### Where are the most listings in Vienna? <a class=\"anchor\" id=\"results-most-listings\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_geo_data():\n",
    "    \"\"\" load geojson data \"\"\"\n",
    "    with open(os.path.join(Path(cwd).parent, 'data', 'geojson', 'vienna.geojson'), encoding='utf-8') as fp:\n",
    "        counties = geojson.load(fp)\n",
    "    return counties\n",
    "\n",
    "def save_figure(fig, name):\n",
    "    with open(f\"{name}.json\", \"w\") as outfile:\n",
    "        outfile.write(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def heatmap_airbnb2(title=''):\n",
    "    \"\"\" \"\"\"\n",
    "    districts = get_geo_data()\n",
    "    k = aggregate_data(df, 'neighbourhood', {'neighbourhood':['first'], 'price':['median'], 'host_is_superhost': ['first']},\\\n",
    "                       rename=['district', 'median', 'host_is_superhost'])\n",
    "    k.sort_values(by='median', ascending=True, inplace=True)\n",
    "    k['median'] = k['median'].astype('category')\n",
    "    k.sort_values(by='median', ascending = False, inplace=True)\n",
    "    fig = px.choropleth_mapbox(k, geojson=districts, locations=k['district'], featureidkey=\"properties.name\", \n",
    "                               color=k['median'],\n",
    "                               title=title,\n",
    "                               color_discrete_sequence=px.colors.qualitative.Prism, \n",
    "                               labels={'median':'price per night'},\n",
    "        mapbox_style=\"open-street-map\", zoom=10, center = {\"lat\": 48.210033, \"lon\": 16.363449}, opacity=0.60)\n",
    "    \n",
    "    fig.add_scattermapbox(\n",
    "        lat=df['latitude'].tolist(),\n",
    "        lon=df['longitude'].tolist(),\n",
    "        mode='markers',\n",
    "        showlegend=False,\n",
    "        #text=texts,\n",
    "        marker_size=5,\n",
    "        marker_color='#F3B5B6',\n",
    "        opacity= 0.5,\n",
    "        hoverinfo='skip'\n",
    "    )\n",
    "    fig.update_layout(font=dict(family=\"Helvetica\"))\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=500)\n",
    "    \n",
    "    save_figure(fig.to_json(), \"test\")\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "def heatmap_airbnb(title=''):\n",
    "    \"\"\" \"\"\"\n",
    "    districts = get_geo_data()\n",
    "    agg = df.groupby('neighbourhood').agg(nr_listings = ('id', 'count')).reset_index().sort_values('nr_listings', ascending=False)\n",
    "    agg['ratio'] = 100 * agg['nr_listings'] / agg['nr_listings'].sum()\n",
    "    agg['nr_listings'] = agg['nr_listings'].astype('category')\n",
    "    agg.sort_values(by='nr_listings', ascending = False, inplace=True)\n",
    "    fig = px.choropleth_mapbox(agg, geojson=districts, locations=agg['neighbourhood'], featureidkey=\"properties.name\",\n",
    "                               color_discrete_sequence=px.colors.qualitative.Dark24,\n",
    "                               color=agg['nr_listings'],\n",
    "                               #color=agg['ratio'],\n",
    "                               title=title,\n",
    "                               labels={'nr_listings':'Nr. of listings'},\n",
    "        mapbox_style=\"open-street-map\", zoom=10, center = {\"lat\": 48.210033, \"lon\": 16.363449}, opacity=0.40)\n",
    "    \n",
    "    fig.add_scattermapbox(\n",
    "        lat=df['latitude'].tolist(),\n",
    "        lon=df['longitude'].tolist(),\n",
    "        mode='markers',\n",
    "        #text=texts,\n",
    "        marker_size=2,\n",
    "        marker_color='#F3F5F6',\n",
    "        opacity= 0.9,\n",
    "        showlegend=True,\n",
    "        hoverinfo='skip' #hoverinfo='none'\n",
    "    )\n",
    "    fig.update_layout(font=dict(family=\"Helvetica\"))\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=500)\n",
    "    \n",
    "    save_figure(fig.to_json(), \"test2\")\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "def bar_airbnb(df):\n",
    "    \"\"\"generates the bar chart of the category distribution from the \"direct\" genre \"\"\"\n",
    "    agg = df.groupby('neighbourhood').agg(nr_listings = ('id', 'count')).reset_index().sort_values('nr_listings', ascending=False)\n",
    "    agg['ratio'] = 100 * agg['nr_listings'] / agg['nr_listings'].sum()\n",
    "    fig = px.bar(x=agg['neighbourhood'].tolist(), y=agg['ratio'])\n",
    "    save_figure(fig.to_json(), \"barchart2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_airbnb(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_airbnb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "with open('test2.json', 'r') as f:\n",
    "    fig = pio.from_json(f.read())\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 11038 listings in Vienna available for renting in the span between September 2021 and September 2022. The most expensive districts are central and nearby the tourists hotspots of the historic inner city. The five districts with the most Airbnb appartments are in following districts: Leopoldstadt, Landstraße, Rudolfsheim-Fünfhaus, Favoriten, Neubau. However, these are not necessarily the most expensive districts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the district affect the price? <a class=\"anchor\" id=\"results-price-district\"></a>\n",
    "\n",
    "The median price per district is depicted in the graphic below. The inner district (Innere Stadt) is significant expensiver than the surrounding districts. However, this district only accounts for 3.6 % of all the listings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_airbnb2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Which are the cheapest and the most expensive districts in Vienna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df.copy()\n",
    "df_p = aggregate_data(df_p, 'neighbourhood', {'neighbourhood':['first', 'count'], 'price':['median']}, rename=['district', 'listings','median'])\n",
    "df_p = df_p.round({'median': 1})\n",
    "df_p.sort_values(by=['median'], na_position='first', ascending=False, inplace=True)\n",
    "df_p.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.sort_values(by='median', ascending=True, inplace=True)\n",
    "df_p.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the composition of room types of Viennas districts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_types_count = df.groupby(['neighbourhood','room_type'], as_index = False)['id'].count()\n",
    "property_types_count = property_types_count.sort_values(by='id', ascending = False)\n",
    "property_types_count['count'] = property_types_count['id']\n",
    "\n",
    "fig = px.sunburst(property_types_count, path=['neighbourhood', 'room_type'],\n",
    "                  values=property_types_count['count'], color='neighbourhood',\n",
    "                  color_discrete_sequence=px.colors.qualitative.Prism) # px.colors.qualitative.G10\n",
    "fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.update_layout(autosize=False,width=600,height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df.copy()\n",
    "df_x['price'] = df_x['price']/df_x['accommodates']\n",
    "df_x = aggregate_data(df_x, 'neighbourhood', {'neighbourhood':['first', 'count'], 'price':['mean', 'median', 'std', 'min', 'max']}, rename=['district', 'count', 'mean', 'median', 'std', 'min', 'max'])\n",
    "df_x = df_x.round({'mean': 1, 'median': 1, 'std': 1, 'min': 1, 'max': 1})\n",
    "df_x.sort_values(by=['median'], na_position='first', ascending=False, inplace=True)\n",
    "df_x.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When is the most suitable time to rent an Airbnb appartment in terms of price and availability?\n",
    "To answer this question the data from the calendar data frame is analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define public holidays for the available time span\n",
    "holidays = {'Christmas Eve': np.datetime64('2019-12-24'),\n",
    "            'New Year': np.datetime64('2020-01-01'),\n",
    "            'Easter Monday': np.datetime64('2020-04-13'),\n",
    "            'Labor Day': np.datetime64('2020-05-01'),\n",
    "            'Ascension': np.datetime64('2020-05-21'),\n",
    "            'Whit Monday': np.datetime64('2020-06-01'),\n",
    "            'Corpus Christi': np.datetime64('2020-06-11'),\n",
    "            'National Holiday Austria': np.datetime64('2020-10-26')}\n",
    "tmp = aggregate_data(df_cal, 'date', {'date':['first'], 'price':['median']}, rename=['date', 'price'])\n",
    "tmp = tmp.iloc[1:-4,:]\n",
    "fig = go.Figure()\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=tmp['date'], y=tmp['price'], showlegend=False, line=dict(color='#2c6e81', width=2))) #line_color=\"#2c6e81\"\n",
    "fig.update_layout(        font=dict(family=\"Open Sans\"),    legend_font_size=14)\n",
    "\"\"\"\n",
    "fig.add_shape(type=\"rect\",\n",
    "                        xref=\"x\",\n",
    "                        yref=\"paper\",\n",
    "                        x0=np.datetime64('2022-10-01'),\n",
    "                        y0=0,\n",
    "                        x1=np.datetime64('2022-12-01'),\n",
    "                        y1=86,\n",
    "                        line=dict(color=\"rgba(0,40,60,0)\",width=3,),\n",
    "                        fillcolor='rgba(100,100,100,0.2)',\n",
    "                        layer='above')\"\"\"\n",
    "fig.update_layout(yaxis_title=\"Median price in $\")\n",
    "#fig.update_layout(xaxis_tick0 = tmp['date'][1], xaxis_dtick=86400000*7)\n",
    "fig.update_layout(xaxis=dict(tickformat=\"%b\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.5. How is the number of reviews changing over time? <a class=\"anchor\" id=\"results-reviews-over-time\"></a>\n",
    "Out of curiousity if there is some trend in the number of reviews. What you can see here is that there is some seasonal influence on the number of reviews, and that airbnb is growing as a platform and more and more people give a review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_reviews_over_time(data_reviews):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "    go.Scatter(x=data_reviews['date'], y=data_reviews['num_reviews'], showlegend=False, line=dict(color='#2c6e81', width=1)))\n",
    "    fig.update_layout( font=dict(family=\"Open Sans\"), legend_font_size=14),\n",
    "    fig.add_trace(go.Scatter(x=data_reviews['date'], y=data_reviews['num_reviews'].rolling(20).mean(), \n",
    "                             name =\"SMA 20\", line=dict(color='orange', width=2), showlegend=True))\n",
    "    # fig.update_layout(xaxis=dict(tickformat=\"%b\"))\n",
    "    fig.update_layout(yaxis_title=\"Nr. of reviews\")\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(legend=dict(yanchor='top',y=.95,xanchor='left',x=0.01))\n",
    "    fig.update_layout(autosize=False,width=700,height=350)\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()\n",
    "\n",
    "df_reviews = df_rev.copy()\n",
    "# Group by on date and count how many reviews were made on that day\n",
    "data_reviews = df_reviews.groupby('date').count()['listing_id'].reset_index()\n",
    "# Reset the column names\n",
    "data_reviews.columns = ['date', 'num_reviews']\n",
    "# Cast the datatype of the date column so that we can use plot_date.\n",
    "data_reviews['date'] = pd.to_datetime(data_reviews['date'])\n",
    "data_reviews.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reviews_over_time(data_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.6. How do weekends affect pricing? <a class=\"anchor\" id=\"results-weekend-price\"></a>\n",
    "For this question we want to find out if there is a significant difference between the distribution mean of weekday and the distribution mean of weekend prices. We will use significance testing for evaluating significance of observed differences:\n",
    "\n",
    "normal distributions with equal variances: independent t-test [7]\n",
    "non-normal distributions with equal variances: Kruskal-Wallis H-test [8]\n",
    "unequal variances: Welch's t-test [9]\n",
    "Below are the helper functions we want to use for performing the statistical comparison on the weekend weekday price sample distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test(d1, d2, alpha):\n",
    "    \"\"\"\n",
    "    t-test on two sample distributions (d1, d2):\n",
    "    - independent t-test for normal and equal variance \n",
    "    - welch's t-test for normal and unequal variance \n",
    "    - welch's t-test for non-normal and unequal variance\n",
    "    - kruskal-wallis h-test for non-normal and equal variance \n",
    "    \"\"\"\n",
    "    # check of equal variance\n",
    "    equal_var = False\n",
    "    W, p = stats.levene(d1, d2)\n",
    "    if p <= alpha:\n",
    "        print(f'group variances unequal: W = {W:.4f}, p = {p:.2e}')\n",
    "        equal_var = False       \n",
    "    else:\n",
    "        print(f'group variances equal: W = {W:.4f}, p = {p:.2e}')\n",
    "        equal_var = True\n",
    "    \n",
    "    # check for normal distribution\n",
    "    normal = False\n",
    "    for d in [d1, d2]:\n",
    "        k2, p = stats.normaltest(d)\n",
    "        if p <= alpha:\n",
    "            print(f'sample distribution not normal')\n",
    "            normal = False\n",
    "    normal = True\n",
    "    \n",
    "    # test select\n",
    "    if not normal and not equal_var:\n",
    "        print('Welch\\'s t-test on non-normal distributed samples with unequal variances selected')\n",
    "        statistic, p = stats.ttest_ind(d1, d2, equal_var = equal_var)\n",
    "    elif not normal and equal_var:\n",
    "        print('Kruskal-Wallis H-test selected')\n",
    "        statistic, p = stats.kruskal(d1, d2, equal_var = equal_var)\n",
    "    else:\n",
    "        print('Independent t-test selected')\n",
    "        statistic, p = stats.ttest_ind(d1, d2, equal_var = equal_var)    \n",
    "    \n",
    "    # t-test interpretation \n",
    "    significant = 'statistically significant' if p <= alpha else 'not statistically significant'\n",
    "    print(f'Mean difference between groups is: {significant}')\n",
    "    print(f'{statistic}, {p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_r = df_cal.copy()\n",
    "df_cal_r = aggregate_data(df_cal_r, 'date', {'date':['first'], 'price':['median'], 'weekend':['first']},rename=['date', 'median', 'weekend'])\n",
    "t_test(df_cal_r.query('`weekend` == True')['median'], df_cal_r.query('`weekend` == False')['median'], alpha = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cal_r.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_comparison_weekends_distribution(weekday, weekend):\n",
    "    \"\"\" \"\"\"\n",
    "    hist_data = [weekday['median'], weekend['median']]\n",
    "    group_labels = ['weekday', 'weekend']\n",
    "    colors = ['#A56CC1', '#A6ACEC']\n",
    "\n",
    "    # Create distplot with curve_type set to 'normal'\n",
    "    fig = ff.create_distplot(hist_data, group_labels, colors=colors, bin_size=1, show_hist=True, show_rug=False)\n",
    "\n",
    "    # Add title\n",
    "    fig.update_layout(title_text='Hist and Curve Plot')\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(autosize=False,width=700,height=350)\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "def price_comparison_weekends(df):\n",
    "    \"\"\" \"\"\"\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Violin(x=df['weekend'],\n",
    "                            y=df['median'],\n",
    "                            name='dff', #legendgroup='median',\n",
    "                            line_color='blue',\n",
    "                            width=0.8, box_visible=True, meanline_visible=True))\n",
    "    fig.update_traces(box_visible=True, meanline_visible=True)\n",
    "    fig.update_layout(violinmode=\"overlay\", violingap=0)\n",
    "    #fig.update_layout(violinmode='group')\n",
    "    fig.update_layout(autosize=False, width=800, height=400)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_comparison_weekends(df_cal_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_comparison_weekends_distribution(df_cal_r.query('`weekend` == False'), df_cal_r.query('`weekend` == True'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Results and Evaluation\n",
    "\n",
    "The mean difference for low price listings is 4.9 %. The t-tests ($\\alpha$ = 0.05) states that the mean difference for the low price category ist statistically significant. Thus we can conclude that for low price category listings weekday prices differ (statistically) significant from weekend prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turn OpenStreetMap Location Data into ML Features <a class=\"anchor\" id=\"osm-features\"></a>\n",
    "#### How to pull shops, restaurants, public transport modes and other local amenities into your ML models\n",
    "With this information it might be possible to find a reasonable model with ammeniteis which affect what a host will charge for an airbnb.\n",
    "\n",
    "##### Define Area of Interest\n",
    "In this case the area of Vienna is imported from a geojson file into a geopandas dataframe. This datframe needs to be converted to a polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_geojson = gpd.read_file(os.path.join(Path(cwd).parent, 'data', 'geojson', 'vienna.geojson'))\n",
    "boundary_geojson.drop(columns=['cartodb_id', 'created_at', 'updated_at'], inplace=True)\n",
    "region = boundary_geojson.geometry.unary_union\n",
    "\n",
    "def get_local_crs(y,x):  \n",
    "    x = ox.utils_geo.bbox_from_point((y, x), dist = 500, project_utm = True, return_crs = True)\n",
    "    return x[-1]\n",
    "  \n",
    "# Set longitude and latitude of Vienna\n",
    "lon_latitude = 48.210033\n",
    "lon_longitude = 16.363449\n",
    "\n",
    "local_utm_crs = get_local_crs(lon_latitude, lon_longitude)\n",
    "# print(f\"boundary data type: {type(boundary_geojson)}, region data type: {type(region)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pull list of all amenities from OSM wiki page for reference\n",
    "To get all the OSM queries especially for amenities, a list with all the keys is displayed from the [Openstreetmap wiki](https://wiki.openstreetmap.org/wiki/Key:amenity). This OSM data is accessible through the osmnx python module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_amenities():\n",
    "    \"\"\" get all amenitiy keys from OSM wiki \"\"\"\n",
    "    try:\n",
    "        amenities = pd.read_html('https://wiki.openstreetmap.org/wiki/Key:amenity', skiprows = 0, header=0, attrs = {'class': 'wikitable'})[0]\n",
    "        amenities.drop(columns=['Element', 'Carto rendering','Photo', 'Unnamed: 6'], inplace=True, axis=1)\n",
    "        amenities.drop(index=0, inplace=True)\n",
    "        return amenities\n",
    "    except Excepion as e:\n",
    "        print(\"Amenities could not be found\")\n",
    "\n",
    "\n",
    "amenities = get_all_amenities()\n",
    "print(f\"First ten amenity keys: {', '.join(amenities['Value'].tolist()[0:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query the OSM location data with osmnx\n",
    "\n",
    "```python\n",
    "def get_osm_data(region, data):\n",
    "    df = ox.geometries.geometries_from_polygon(region, tags=data[0])\n",
    "    df.to_csv(os.path.join(Path(cwd).parent, 'data', 'osm', \n",
    "                           f'{list(data[0].values())[0]}.csv'), columns=['geometry'])\n",
    "    return df\n",
    "\n",
    "t0 = time.time()\n",
    "cafe = get_osm_data(region, [{'amenity':'cafe'}])\n",
    "restaurant = get_osm_data(region, [{'amenity':'restaurant'}])\n",
    "attraction = get_osm_data(region, [{'tourism':'attraction'}])\n",
    "station = get_osm_data(region, [{'station':'subway'}])\n",
    "bar = get_osm_data(region, [{'amenity':'bar'}])\n",
    "biergarten = get_osm_data(region, [{'amenity':'biergarten'}])\n",
    "fast_food = get_osm_data(region, [{'amenity':'fast_food'}])\n",
    "pub = get_osm_data(region, [{'amenity':'pub'}])\n",
    "nightclub = get_osm_data(region, [{'amenity':'nightclub'}])\n",
    "theatre = get_osm_data(region, [{'amenity':'theatre'}])\n",
    "university = get_osm_data(region, [{'amenity':'university'}])\n",
    "attraction = get_osm_data(region, [{'tourism':'attraction'}])\n",
    "shop = get_osm_data(region, [{'shop':'supermarket'}])\n",
    "\n",
    "roads = ox.graph.graph_from_polygon(region)\n",
    "forest = ox.geometries.geometries_from_polygon(region, tags = {'landuse': 'forest'})\n",
    "rivers = ox.geometries.geometries_from_polygon(region, tags = {'waterway': 'river'})\n",
    "#building: True means that every type of buildings will be downloaded\n",
    "#buildings = ox.geometries.geometries_from_polygon(region, tags = {'building': True})\n",
    "#kindergarten = ox.geometries.geometries_from_polygon(region, tags = {'amenity':'kindergarten'})\n",
    "#secondary_roads = ox.geometries.geometries_from_polygon(region, tags = {'highway': 'secondary'})\n",
    "print (f\"Completed in {round(time.time() - t0)} s\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_to_gpd(name):\n",
    "    \"\"\" import the csv file a gepandas dataframe \"\"\"\n",
    "    df = pd.read_csv(os.path.join(Path(cwd).parent, 'data', 'osm', f'{name}.csv'), sep=\",\")\n",
    "    df['geometry'] = df['geometry'].apply(wkt.loads)\n",
    "    gdf = gpd.GeoDataFrame(df, crs='epsg:4326')\n",
    "    return gdf\n",
    "\n",
    "restaurant = import_csv_to_gpd('restaurant')\n",
    "cafe = import_csv_to_gpd('cafe')\n",
    "attraction = import_csv_to_gpd('attraction')\n",
    "subway = import_csv_to_gpd('subway')\n",
    "bar = import_csv_to_gpd('bar')\n",
    "biergarten = import_csv_to_gpd('biergarten')\n",
    "fast_food = import_csv_to_gpd('fast_food')\n",
    "pub = import_csv_to_gpd('pub')\n",
    "nightclub = import_csv_to_gpd('nightclub')\n",
    "theatre = import_csv_to_gpd('theatre')\n",
    "university= import_csv_to_gpd('university')\n",
    "shop = import_csv_to_gpd('supermarket')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization of OSM Features:\n",
    "\n",
    "```python\n",
    "ax = boundary_geojson.plot(facecolor = '#494D4D', figsize=(85,85))\n",
    "ax.set_facecolor('#2C2E2E')\n",
    "#buildings['geometry'].plot(facecolor = '#C61313', edgecolor = '#C61313', linewidth = 3, markersize = 1, ax = ax)\n",
    "forest.plot(facecolor = '#494D4D', edgecolor = '#ADC3B8', linewidth = 2, linestyle = ':', hatch ='x', ax=ax)\n",
    "rivers.plot(edgecolor='#67A0C3', linewidth=6, linestyle='-', ax=ax)\n",
    "ox.plot_graph(roads, edge_color='white', node_color='white', edge_linewidth=2, node_size=2, ax=ax)\n",
    "ax.grid('on', which='major', axis='x', color = '#99A2A2')\n",
    "ax.grid('on', which='major', axis='y', color = '#99A2A2')\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turning the Data Into Features\n",
    "What we currently have is a dataframe of all the restaurants in London. For a machine learning model, what we need is the number of restaurants within a 10-minute walk each Airbnb property. Quite a bit of manipulation is required to get to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geo dataframe has a column defining the geometry (e.g. POINT, POLYGON, Mult-Polygon). Restaurant locations for instance come as a point object and the latitude and longitude coordination need to be extracted.\n",
    "\n",
    "##### Convert Polygons into Points\n",
    "Most properties are returned as a single point coordinate. However, some are returned in a different shape e.g POLYGON, MulitPOLYGON or LINESTRING (e.g. on larger properties). In order to work with polygons, only their center point is used for subsequent feature extraction and modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lat_long(point):\n",
    "    \"\"\" get latitude and longitude coordinate from POINT geometry \"\"\"\n",
    "    try:\n",
    "        return pd.Series([point.x, point.y])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "def geo_coordinates(df):\n",
    "    \"\"\" import from csv in geopandas dataframe\n",
    "    source: https://stackoverflow.com/questions/61122875/geopandas-how-to-read-a-csv-and-convert-to-a-geopandas-dataframe-with-polygons\n",
    "    \"\"\"\n",
    "    df['geometry'] = df['geometry'].apply(lambda x: x.centroid if type(x) == Polygon else (x.centroid if type(x) == MultiPolygon else x))\n",
    "    df[['long', 'lat']] = df.apply(lambda x: get_lat_long(x['geometry']), axis=1)\n",
    "    df = df[df['geometry'].apply(lambda x : x.type=='Point' )]\n",
    "    df = df.to_crs(local_utm_crs)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant = geo_coordinates(restaurant)\n",
    "cafe = geo_coordinates(cafe)\n",
    "bar = geo_coordinates(bar)\n",
    "subway = geo_coordinates(subway)\n",
    "biergarten = geo_coordinates(biergarten)\n",
    "fast_food = geo_coordinates(fast_food)\n",
    "pub = geo_coordinates(pub)\n",
    "nightclub = geo_coordinates(nightclub)\n",
    "theatre = geo_coordinates(theatre)\n",
    "university = geo_coordinates(university)\n",
    "attraction = geo_coordinates(attraction)\n",
    "shop = geo_coordinates(shop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate Distances with a KD Tree\n",
    "Iterate through each AirBnb property and work out how many respective Openstreetmap features there are within a radius of 1 km. This is done using a KD Tree which is an efficient way of searching through our 12,000 AirBnbs rooms and thousend of features figuring out which ones are close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(df):\n",
    "    try:\n",
    "        # turn long/lats into a list\n",
    "        coords = list(zip(df.geometry.apply(lambda x: x.y).values,df.geometry.apply(lambda x: x.x).values))\n",
    "        # create a KDTree\n",
    "        tree = spatial.KDTree(coords)\n",
    "        return tree\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a next step a function is created which is performed on each of the Airbnb properties. The function will query the tree and find the 500 closest restaurants along with calculating their distances from the Airbnb property. We use a figure of 500 in the hope that no property has more than 500 restaurants close to it.\n",
    "With this approach it can be determined how many restaurants, bars, shops, subway stations, tourist hotspots, public parks etc. there are within a 10-minute walk of each Airbnb property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_points_closeby(tree, lat_lon, k = 500, max_distance = 500 ):\n",
    "    results = tree.query((lat_lon), k = k, distance_upper_bound= max_distance)\n",
    "    zipped_results = list(zip(results[0], results[1]))\n",
    "    zipped_results = [i for i in zipped_results if i[0] != np.inf]\n",
    "    return len(zipped_results)\n",
    "\n",
    "t0 = time.time()\n",
    "air_gdf = df.copy()\n",
    "\n",
    "parameters = [restaurant, cafe , bar, subway, biergarten, fast_food, pub, nightclub,theatre,university,attraction]\n",
    "names = ['restaurant', 'cafe', 'bar', 'subway', 'biergarten', 'fast_food', 'pub', 'nightclub','theatre','university','attraction']\n",
    "\n",
    "air_gdf = gpd.GeoDataFrame(air_gdf, geometry = gpd.points_from_xy(air_gdf.longitude, air_gdf.latitude), crs = 4326)\n",
    "air_gdf = air_gdf.to_crs(local_utm_crs)\n",
    "\n",
    "for name, i in zip(names, parameters):\n",
    "    tree = get_tree(i)\n",
    "    air_gdf[name] = air_gdf.apply(lambda row: find_points_closeby(tree, (row.geometry.y, row.geometry.x)) , axis = 1)\n",
    "\n",
    "print (f\"Completed in {round(time.time() - t0)} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "sns.heatmap(air_gdf.corr(), ax=ax, annot=True, fmt=\".2f\");\n",
    "# fig.savefig(\"correlation-matrix.png\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_amenities(fig, df, showlegend=True, name='', marker_color='rgb(135, 60, 200)', marker_size=5, marker='circle'):\n",
    "    fig.add_scattermapbox(\n",
    "        lat=df.lat.tolist(),\n",
    "        lon=df.long.tolist(),\n",
    "        #marker_symbol=marker,\n",
    "        mode='markers', #'markers+text'\n",
    "        #text=texts,\n",
    "        #marker = marker,\n",
    "        marker_size=marker_size,\n",
    "        marker_color=marker_color,\n",
    "        opacity= 0.8,\n",
    "        showlegend=showlegend,\n",
    "                #hover_data=['amenity'],\n",
    "       # hoverinfo='restaurant'\n",
    "      #  label={'trace 1':'test'},\n",
    "        name=name)\n",
    "\n",
    "def heatmap(df, title=''):\n",
    "    \"\"\" selector specifies the geographic resolution \n",
    "    source: https://stackoverflow.com/questions/67680264/combining-mapbox-choropleth-with-additional-layers-and-markers-in-python-try-to\n",
    "    additional markers : https://plotly.github.io/plotly.py-docs/generated/plotly.express.scatter_mapbox.html\n",
    "    https://plotly.com/python/scatter-plots-on-maps/\n",
    "    \"\"\"\n",
    "    feat_key = ''\n",
    "    locations = ''\n",
    "    hover_data = ''\n",
    "    j = get_geo_data()\n",
    "    fig = px.choropleth_mapbox(df, geojson=j, locations=test['name'], featureidkey=\"properties.name\", color=test['value'],\n",
    "                               title=title,\n",
    "        mapbox_style=\"open-street-map\", zoom=10, center = {\"lat\": 48.210033, \"lon\": 16.363449}, opacity=0.15)\n",
    "    \n",
    "    lons = [item['geometry']['coordinates'][0][0][0][1] for item in j['features']]\n",
    "    lats = [item['geometry']['coordinates'][0][0][0][0] for item in j['features']]\n",
    "    texts = [item['properties']['name'] for item in j['features']]\n",
    "\n",
    "    marker = itertools.cycle(('circle')) \n",
    "    add_amenities(fig, fast_food, name='Restaurants', marker_color='rgb(240, 240, 200)', marker_size=12, marker=next(marker))\n",
    "    add_amenities(fig, pub, name='Pubs', marker_color='rgb(255, 87, 200)', marker_size=1, marker=next(marker)) \n",
    "   \n",
    "    add_amenities(fig, bar, name='Bar', marker_color='rgb(135, 60, 200)', marker_size=5, marker=next(marker))\n",
    "    add_amenities(fig, cafe, name='Cafe', marker_color='rgb(135, 60, 200)', marker_size=7, marker=next(marker))    \n",
    "    add_amenities(fig, fast_food, name='Fast food', marker_color='rgb(135, 60, 200)', marker_size=8, marker=next(marker)) \n",
    "    add_amenities(fig, subway, name='Subway', marker_color='rgb(135, 60, 200)', marker_size=6, marker=next(marker)) \n",
    "    add_amenities(fig, biergarten, name='Biergarten', marker_color='rgb(135, 60, 200)', marker_size=5, marker=next(marker)) \n",
    "    add_amenities(fig, attraction, name='Attraction', marker_color='rgb(135, 60, 200)', marker_size=5, marker=next(marker)) \n",
    "    add_amenities(fig, university, name='University', marker_color='rgb(40, 120, 43)', marker_size=2, marker=next(marker)) \n",
    "    add_amenities(fig, nightclub, name='Nightclub', marker_color='rgb(45, 67, 12)', marker_size=5, marker=next(marker))\n",
    "\n",
    "    fig.update_coloraxes(showscale=False)\n",
    "    fig.update_layout(paper_bgcolor='rgba(0,0,0,0)', plot_bgcolor='rgba(0,0,0,0)')\n",
    "    fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "    fig.update_layout(autosize=False,width=700,height=500)\n",
    "    fig.show()\n",
    "\n",
    "test = boundary_geojson.copy()\n",
    "\n",
    "test.reset_index(inplace=True)\n",
    "test['value'] =  test['index']*1.2\n",
    "heatmap(boundary_geojson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, make_scorer\n",
    "\n",
    "def display_results(cv, y_test, y_pred):\n",
    "    \"\"\" check how well the model performs. \"\"\"\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nBest Parameters:\", cv.best_params_)\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, category_names):\n",
    "    \"\"\" evaluate how well the given model performs with test data set \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    class_report = classification_report(y_test, y_pred, target_names=category_names)\n",
    "    print(class_report)\n",
    "\n",
    "def save_model(model, model_filepath):\n",
    "    \"\"\" save model as a .pkl file under a give file path \"\"\"\n",
    "    with open(model_filepath, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "\n",
    "\n",
    "# Separate the target variable and rest of the variables\n",
    "X, y = air_gdf[['restaurant','cafe', 'bar', 'subway','biergarten','fast_food','pub','nightclub',\n",
    "                'theatre','university']], air_gdf['price']\n",
    "\n",
    "# Convert the dataset into an optimized data structure called Dmatrix that XGBoost supports and gives it acclaimed performance and efficiency gains. You will use this later in the tutorial.\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=123)\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "save_model(model, os.path.join(Path(cwd).parent, 'model', 'xboost.pkl'))\n",
    "\n",
    "# feature importance\n",
    "print(model.feature_importances_)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "# Compute the rmse by invoking the mean_sqaured_error function from sklearn's metrics module.\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "params = {}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"rmse\", as_pandas=True, seed=123)\n",
    "\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))\n",
    "\n",
    "xgb.plot_importance(model)\n",
    "plt.rcParams['figure.figsize'] = [6, 6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example to predict benchmark price\n",
    "d = {'restaurant': 3, 'cafe': 100, 'bar':5, 'subway':3, 'biergarten':1, 'fast_food':15, 'pub':3,\n",
    "    'nightclub':1,'theatre':0,'university':0}\n",
    "X_pred = pd.DataFrame(data=d, index=[0])\n",
    "preds = model.predict(X_pred)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "In my final XGBoost model, as you can see below, these OSM features (highlighted in red) ended up being some of the most important drivers of price in London."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Convert notebook to html\n",
    "```python\n",
    "!jupyter nbconvert --to html Airbnb-Analysis.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download notebook to html\n",
    "!jupyter nbconvert --to html Airbnb-Analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.path.join(Path(cwd).parent, 'data', f'airbnb_dataframe.csv'), columns=['id', 'price', 'latitude', 'longitude', 'neighbourhood'], sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
